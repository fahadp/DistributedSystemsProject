\section{Introduction}

‘Big data’ is getting even bigger due to explosive growth in computing devices, infrastructure and the amount of time users spend online. Much of this data is widely distributed due to the global presence of major cellular and cloud service providers,  and search and social networking platforms. For example, the data generated and stored by Google’s internal infrastructure, as well as user data collected through its search and advertising services are spread over its multiple datacenters. Similarly a cellular provider's switching and serving infrastructure in a single metropolitan area alone consists of hundreds of base stations, each collecting gigabytes of data, and each connected to its neighbors via a bandwidth-constrained link. In such networks,  backhauling data back to a central server to perform analytics tasks would be slow and impractical, making real-time analytics challenging.

MapReduce is a parallel programming model widely used to analyze large data sets. Traditional MapReduce models assume data stored and jobs scheduled in a single cluster, and is not suitable for an heterogeneous environment where the input data is distributed among multiple clusters. Traditional MapReduce models rely on a shared filesystem, such as HDFS, accessible to all nodes through which data has to transit to be scheduled to the worker nodes. Backhauling all the data to a central location quickly becomes slow and expensive over a wide-area network because bandwidth is a scarce resource.

When processing large amounts of physically distributed data, users may prefer a “quick and dirty” result over a correct answer that could take much longer to compute \cite{3, 4}. To this end, we wish to develop a MapReduce infrastructure for data processing on wide-area networks that minimizes communication on expensive links at the expense of result correctness. We explore two ways to reduce data exchange on expensive links between physically distributed nodes: (1) performing the map-reduce jobs locally on each data-center while periodically updating results across data centers, and (2) by reducing the size of the updates sent across data-centers. The first approach could affect convergence and correctness of the results if updates are not frequent enough (see PageRank). The second approach is applicable to a restricted set of queries discussed below (see Top-K).